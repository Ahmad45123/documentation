{"basic configuration": "## Basic Configuration ##\n## @param api_key - string - required\n## @env DD_API_KEY - string - required\n## The Datadog API key to associate your Agent's data with your organization.\n## Create a new API key here: https://app.datadoghq.com/account/settings\n## @param site - string - optional - default: datadoghq.com\n## @env DD_SITE - string - optional - default: datadoghq.com\n## The site of the Datadog intake to send Agent data to.\n## Set to 'datadoghq.eu' to send data to the EU site.\n## Set to 'us3.datadoghq.com' to send data to the US3 site.\n## Set to 'ddog-gov.com' to send data to the US1-FED site.\n site: datadoghq.com\n\n## @param dd_url - string - optional - default: https://app.datadoghq.com\n## @env DD_URL - string - optional - default: https://app.datadoghq.com\n## The host of the Datadog intake server to send metrics to, only set this option\n## if you need the Agent to send metrics to a custom URL, it overrides the site\n## setting defined in \"site\". It does not affect APM, Logs or Live Process intake which have their\n## own \"*_dd_url\" settings.\n dd_url: https://app.datadoghq.com\n\n## @param proxy - custom object - optional\n## If you need a proxy to connect to the Internet, provide it here (default:\n## disabled). Refer to https://docs.datadoghq.com/agent/proxy/ to understand how to use these settings.\n## For Logs proxy information, refer to https://docs.datadoghq.com/agent/proxy/#proxy-for-logs\n proxy:\n\n   https: http://<USERNAME>:<PASSWORD>@<PROXY_SERVER_FOR_HTTPS>:<PORT>\n\n   http: http://<USERNAME>:<PASSWORD>@<PROXY_SERVER_FOR_HTTP>:<PORT>\n\n   no_proxy:\n\n     - <HOSTNAME-1>\n\n     - <HOSTNAME-2>\n\n## @param skip_ssl_validation - boolean - optional - default: false\n## Setting this option to \"true\" tells the Agent to skip validation of SSL/TLS certificates.\n skip_ssl_validation: false\n\n## @param force_tls_12 - boolean - optional - default: false\n## Setting this option to \"true\" forces the Agent to only use TLS 1.2 when\n## pushing data to the Datadog intake specified in \"site\" or \"dd_url\".\n force_tls_12: false\n\n## @param hostname - string - optional - default: auto-detected\n## Force the hostname name.\n hostname: <HOSTNAME_NAME>\n\n## @param hostname_file - string - optional\n## In some environments, auto-detection of the hostname is not adequate and\n## environment variables cannot be used to set the value. In such cases, the\n## file on the host can also be used provide an appropriate value. If\n## 'hostname' value has been set to a non-empty value, this option is ignored.\n hostname_file: /var/lib/cloud/data/instance-id\n\n## @param hostname_fqdn - boolean - optional - default: false\n## When the Agent relies on the OS to determine the hostname, make it use the\n## FQDN instead of the short hostname. Recommended value: true\n## More information at https://dtdg.co/flag-hostname-fqdn\n hostname_fqdn: false\n\n## @param host_aliases - list of strings - optional\n## List of host aliases to report in addition to any aliases collected\n## automatically from cloud providers.\n## More information at\n## https://docs.datadoghq.com/agent/faq/how-datadog-agent-determines-the-hostname/?tab=agentv6v7#host-aliases\n host_aliases:\n\n   - <ALIAS-1>\n\n   - <ALIAS-2>\n\n## @param tags  - list of key:value elements - optional\n## List of host tags. Attached in-app to every metric, event, log, trace, and service check emitted by this Agent.\n##\n## Additional tags can be supplied using the `DD_EXTRA_TAGS` environment variable.\n##\n## Learn more about tagging: https://docs.datadoghq.com/tagging/\n tags:\n\n   - environment:dev\n\n   - <TAG_KEY>:<TAG_VALUE>\n\n## @param env - string - optional\n## The environment name where the agent is running. Attached in-app to every\n## metric, event, log, trace, and service check emitted by this Agent.\n env: <environment name>\n\n## @param tag_value_split_separator - map - optional\n## Split tag values according to a given separator. Only applies to host tags,\n## and tags coming from container integrations. It does not apply to tags on dogstatsd metrics,\n## and tags collected by other integrations.\n##\n## Example use-case:\n##\n##  With a raw collected tag \"foo:1;2;3\", using the following configuration:\n##\n##  tag_value_split_separator:\n##    foo: ;\n##\n##  results in the raw tag being transformed into \"foo:1\", \"foo:2\", \"foo:3\" tags\n tag_value_split_separator:\n\n   <TAG_KEY>: <SEPARATOR>\n\n## @param checks_tag_cardinality - string - optional - default: low\n## Configure the level of granularity of tags to send for checks metrics and events. Choices are:\n##   * low: add tags about low-cardinality objects (clusters, hosts, deployments, container images, ...)\n##   * orchestrator: add tags about pod, (in Kubernetes), or task (in ECS or Mesos) -level of cardinality\n##   * high: add tags about high-cardinality objects (individual containers, user IDs in requests, ...)\n## WARNING: sending container tags for checks metrics may create more metrics\n## (one per container instead of one per host). This may impact your custom metrics billing.\n checks_tag_cardinality: low\n\n## @param dogstatsd_tag_cardinality - string - optional - default: low\n## Configure the level of granularity of tags to send for DogStatsD metrics and events. Choices are:\n##   * low: add tags about low-cardinality objects (clusters, hosts, deployments, container images, ...)\n##   * orchestrator: add tags about pod, (in Kubernetes), or task (in ECS or Mesos) -level of cardinality\n##   * high: add tags about high-cardinality objects (individual containers, user IDs in requests, ...)\n##\n## WARNING: sending container tags for dogstatsd metrics may create more metrics\n## (one per container instead of one per host). This may impact your custom metrics billing.\n dogstatsd_tag_cardinality: low\n\n## @param histogram_aggregates - list of strings - optional - default: [\"max\", \"median\", \"avg\", \"count\"]\n## Configure which aggregated value to compute.\n## Possible values are: min, max, median, avg, sum and count.\n histogram_aggregates:\n\n   - max\n\n   - median\n\n   - avg\n\n   - count\n\n## @param histogram_percentiles - list of strings - optional - default: [\"0.95\"]\n## Configure which percentiles are computed by the Agent. It must be a list of float between 0 and 1.\n## Warning: percentiles must be specified as yaml strings\n histogram_percentiles:\n\n   - \"0.95\"\n\n## @param histogram_copy_to_distribution - boolean - optional - default: false\n## Copy histogram values to distributions for true global distributions (in beta)\n## Note: This increases the number of custom metrics created.\n histogram_copy_to_distribution: false\n\n## @param histogram_copy_to_distribution_prefix - string - optional\n## A prefix to add to distribution metrics created when histogram_copy_to_distributions is true\n histogram_copy_to_distribution_prefix: \"<PREFIX>\"\n\n## @param aggregator_stop_timeout - integer - optional - default: 2\n## When stopping the agent, the Aggregator will try to flush out data ready for\n## aggregation (metrics, events, ...). Data are flushed to the Forwarder in order\n## to be sent to Datadog, therefore the Agent might take at most\n## 'aggregator_stop_timeout'+'forwarder_stop_timeout' seconds to exit.\n##\n## You can set the maximum amount of time, in seconds, allocated to the\n## Aggregator to do so. You can disable this feature by setting\n## 'aggregator_stop_timeout' to 0.\n aggregator_stop_timeout: 2\n\n @param aggregator_buffer_size - integer - optional - default: 100\n\n The default buffer size for the aggregator use a sane value for most of the\n\n use cases, however, it could be useful to manually set it in order to trade\n\n RSS usage with better performances.\n\n aggregator_buffer_size: 100\n\n## @param forwarder_timeout - integer - optional - default: 20\n## Forwarder timeout in seconds\n forwarder_timeout: 20\n\n## @param forwarder_retry_queue_payloads_max_size - integer - optional - default: 15728640 (15MB)\n## It defines the maximum size in bytes of all the payloads in the forwarder's retry queue.\n## The actual memory used is greater than the payloads size as there are extra fields like HTTP headers,\n## but no more than 2.5 times the payload size.\n forwarder_retry_queue_payloads_max_size: 15728640\n\n## @param forwarder_num_workers - integer - optional - default: 1\n## The number of workers used by the forwarder.\n forwarder_num_workers: 1\n\n## @param forwarder_stop_timeout - integer - optional - default: 2\n## When stopping the agent, the Forwarder will try to flush all new\n## transactions (not the ones in retry state).  New transactions will be created\n## as the Aggregator flush it's internal data too, therefore the Agent might take\n## at most 'aggregator_stop_timeout'+'forwarder_stop_timeout' seconds to exit.\n##\n## You can set the maximum amount of time, in seconds, allocated to the\n## Forwarder to send those transactions.  You can disable this feature by setting\n## 'forwarder_stop_timeout' to 0.\n forwarder_stop_timeout: 2\n\n## @param forwarder_storage_max_size_in_bytes - int - optional - default: 0\n## When the retry queue of the forwarder is full, `forwarder_storage_max_size_in_bytes`\n## defines the amount of disk space the Agent can use to store transactions on the disk.\n## When `forwarder_storage_max_size_in_bytes` is `0`, the transactions are never stored on the disk.\n forwarder_storage_max_size_in_bytes: 50000000\n\n## @param forwarder_storage_max_disk_ratio - float - optional - default: 0.95\n## `forwarder_storage_max_disk_ratio` defines the disk capacity limit for storing transactions.\n## `0.95` means the Agent can store transactions on disk until `forwarder_storage_max_size_in_bytes`\n## is reached or when the disk mount for `forwarder_storage_path` exceeds 95% of the disk capacity,\n## whichever is lower.\n forwarder_storage_max_disk_ratio: 0.95\n\n## @param forwarder_outdated_file_in_days - int - optional - default: 10\n## This value specifies how many days the overflow transactions will remain valid before\n## being discarded. During the Agent restart, if a retry file contains transactions that were\n## created more than `forwarder_outdated_file_in_days` days ago, they are removed.\n forwarder_outdated_file_in_days: 10\n\n## @param cloud_provider_metadata - list of strings -  optional - default: [\"aws\", \"gcp\", \"azure\", \"alibaba\"]\n## This option restricts which cloud provider endpoint will be used by the\n## agent to retrieve metadata. By default the agent will try # AWS, GCP, Azure\n## and alibaba providers. Some cloud provider are not enabled by default to not\n## trigger security alert when querying unknown IP (for example, when enabling\n## Tencent on AWS).\n## Setting an empty list will disable querying any cloud metadata endpoints\n## (falling back on system metadata). Disabling metadata for the cloud provider in which an Agent runs may result in\n## duplicated hosts in your Datadog account and missing Autodiscovery features\n##\n## Possible values are:\n## \"aws\"     AWS EC2, ECS/Fargate\n## \"gcp\"     Google Cloud Provider\n## \"azure\"   Azure\n## \"alibaba\" Alibaba\n## \"tencent\" Tencent\n cloud_provider_metadata:\n\n   - \"aws\"\n\n   - \"gcp\"\n\n   - \"azure\"\n\n   - \"alibaba\"\n\n## @param collect_ec2_tags - boolean - optional - default: false\n## Collect AWS EC2 custom tags as host tags.\n## Requires the EC2 instance to have an IAM role with the `EC2:DescribeTags`\n## permission. See docs for further details:\n## https://docs.datadoghq.com/integrations/faq/how-do-i-pull-my-ec2-tags-without-using-the-aws-integration/\n collect_ec2_tags: false\n\n## @param ec2_metadata_timeout - integer - optional - default: 300\n## Timeout in milliseconds on calls to the AWS EC2 metadata endpoints.\n ec2_metadata_timeout: 300\n\n## @param ec2_prefer_imdsv2 - boolean - optional - default: false\n## If this flag is true then the agent will request EC2 metadata using IMDS v2,\n## which offers additional security for accessing metadata. However, in some\n## situations (such as a containerized agent on a plain EC2 instance) it may\n## require additional configuration on the AWS side. See the AWS guidelines\n## for further details:\n## https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html#instance-metadata-transition-to-version-2\n ec2_prefer_imdsv2: false\n\n## @param collect_gce_tags - boolean - optional - default: true\n## Collect Google Cloud Engine metadata as host tags\n collect_gce_tags: true\n\n## @param exclude_gce_tags - list of strings - optional - default: [\"kube-env\", \"kubelet-config\", \"containerd-configure-sh\", \"startup-script\", \"shutdown-script\", \"configure-sh\", \"sshKeys\", \"ssh-keys\", \"user-data\", \"cli-cert\", \"ipsec-cert\", \"ssl-cert\", \"google-container-manifest\", \"bosh_settings\"]\n## Google Cloud Engine metadata attribute to exclude from being converted into\n## host tags -- only applicable when collect_gce_tags is true.\n exclude_gce_tags:\n\n   - \"kube-env\"\n\n   - \"kubelet-config\"\n\n   - \"containerd-configure-sh\"\n\n   - \"startup-script\"\n\n   - \"shutdown-script\"\n\n   - \"configure-sh\"\n\n   - \"sshKeys\"\n\n   - \"ssh-keys\"\n\n   - \"user-data\"\n\n   - \"cli-cert\"\n\n   - \"ipsec-cert\"\n\n   - \"ssl-cert\"\n\n   - \"google-container-manifest\"\n\n   - \"bosh_settings\"\n\n## @param gce_send_project_id_tag - bool - optional - default: false\n## Send the project ID host tag with the `project_id:` tag key in addition to\n## the `project:` tag key.\n gce_send_project_id_tag: false\n\n## @param gce_metadata_timeout - integer - optional - default: 1000\n## Timeout in milliseconds on calls to the GCE metadata endpoints.\n gce_metadata_timeout: 1000\n\n## @param azure_hostname_style - string - optional - default: \"os\"\n## Changes how agent hostname is set on Azure virtual machines.\n##\n## Possible values:\n##   \"os\" - use the hostname reported by the operating system (default)\n##   \"name\" - use the instance name\n##   \"name_and_resource_group\" - use a combination of the instance name and resource group name\n##   \"full\" - use a combination of the instance name, resource group name and subscription id\n##   \"vmid\" - use the instance id\n azure_hostname_style: \"os\"\n\n## @param flare_stripped_keys - list of strings - optional\n## By default, the Agent removes known sensitive keys from Agent and Integrations yaml configs before\n## including them in the flare.\n## Use this parameter to define additional sensitive keys that the Agent should scrub from\n## the yaml files included in the flare.\n flare_stripped_keys:\n\n   - \"sensitive_key_1\"\n\n   - \"sensitive_key_2\"\n\n## @param no_proxy_nonexact_match - boolean - optional - default: false\n## Enable more flexible no_proxy matching. See https://godoc.org/golang.org/x/net/http/httpproxy#Config\n## for more information on accepted matching criteria.\n no_proxy_nonexact_match: false\n\n## @param use_proxy_for_cloud_metadata - boolean - optional - default: false\n## By default cloud provider IP's are added to the transport's `no_proxy` list.\n## Use this parameter to remove them from the `no_proxy` list.\n use_proxy_for_cloud_metadata: false\n\n## @param python_version - integer - optional - default: 2\n## The major version of Python used to run integrations and custom checks.\n## The only supported values are 2 (to use Python 2) or 3 (to use Python 3).\n## Do not change this option when using the official Docker Agent images.\n python_version: 2\n\n", "advanced configuration": "## Advanced Configuration ##\n## @param confd_path - string - optional\n## The path containing check configuration files. By default, uses the conf.d folder\n## located in the Agent configuration folder.\n confd_path: \"\"\n\n## @param additional_checksd - string - optional\n## Additional path indicating where to search for Python checks. By default, uses the checks.d folder\n## located in the Agent configuration folder.\n additional_checksd: <CHECKD_FOLDER_PATH>\n\n## @param expvar_port - integer - optional - default: 5000\n## The port for the go_expvar server.\n expvar_port: 5000\n\n## @param cmd_port - integer - optional - default: 5001\n## The port on which the IPC api listens.\n cmd_port: 5001\n\n## @param GUI_port - integer - optional\n## The port for the browser GUI to be served.\n## Setting 'GUI_port: -1' turns off the GUI completely\n## Default is:\n##  * Windows & macOS : `5002`\n##  * Linux: `-1`\n##\n GUI_port: <GUI_PORT>\n\n## @param health_port - integer - optional - default: 0\n## The Agent can expose its health check on a dedicated http port.\n## This is useful for orchestrators that support http probes.\n## Default is 0 (disabled), set a valid port number (eg. 5555) to enable.\n health_port: 0\n\n## @param check_runners - integer - optional - default: 4\n## The `check_runners` refers to the number of concurrent check runners available for check instance execution.\n## The scheduler attempts to spread the instances over the collection interval and will _at most_ be\n## running the number of check runners instances concurrently.\n## Setting the value to 1 would result in checks running sequentially.\n##\n## This is a sensitive setting, and we do NOT recommend changing the default number\n## of check runners in the general case. The level of concurrency has effects on\n## the Agent's: RSS memory, CPU load, resource contention overhead, etc.\n check_runners: 4\n\n## @param enable_metadata_collection - boolean - optional - default: true\n## Metadata collection should always be enabled, except if you are running several\n## agents/dsd instances per host. In that case, only one Agent should have it on.\n## WARNING: disabling it on every Agent leads to display and billing issues.\n enable_metadata_collection: true\n\n## @param enable_gohai - boolean - optional - default: true\n## Enable the gohai collection of systems data.\n enable_gohai: true\n\n## @param server_timeout - integer - optional - default: 15\n## IPC api server timeout in seconds.\n server_timeout: 15\n\n## @param procfs_path - string - optional\n## Some environments may have the procfs file system mounted in a miscellaneous\n## location. The procfs_path configuration parameter provides a mechanism to\n## override the standard default location: '/proc' - this setting trickles down to\n## integrations and affect their behavior if they rely on the psutil python package.\n procfs_path: <PROCFS_PATH>\n\n## @param disable_py3_validation - boolean - optional - default: false\n## Disable Python3 validation of python checks.\n disable_py3_validation: false\n\n## @param python3_linter_timeout - integer - optional - default: 120\n## Timeout in seconds for validation of compatibility with python 3 when running python 2.\n python3_linter_timeout: 120\n\n## @param memtrack_enabled - boolean - optional - default: true\n## Enables tracking of memory allocations made from the python runtime loader.\n memtrack_enabled: true\n\n## @param tracemalloc_debug - boolean - optional - default: false\n## Enables debugging with tracemalloc for python checks.\n## Please note that this option is only available when python_version is set to \"3\".\n## Additionally when this option becomes effective the number of check runners is\n## overridden to 1.\n tracemalloc_debug: false\n\n## @param tracemalloc_include - string - optional\n## Comma-separated list of Python checks to enable tracemalloc for when `tracemalloc_debug` is true.\n## By default, all Python checks are enabled.\n tracemalloc_include: <TRACEMALLOC_EXCLUDE>\n\n## @param tracemalloc_exclude - string - optional\n## Comma-separated list of Python checks to disable tracemalloc for when `tracemalloc_debug` is true.\n## By default, all Python checks are enabled. This setting takes precedence over `tracemalloc_include`.\n tracemalloc_exclude: <TRACEMALLOC_INCLUDE>\n\n## @param windows_use_pythonpath - boolean - optional\n## Whether to honour the value of the PYTHONPATH env var when set on Windows.\n## Disabled by default, so we only load Python libraries bundled with the Agent.\n windows_use_pythonpath: false\n\n## @param secret_backend_command - string - optional\n## `secret_backend_command` is the path to the script to execute to fetch secrets.\n## The executable must have specific rights that differ on Windows and Linux.\n##\n## For more information see: https://github.com/DataDog/datadog-agent/blob/main/docs/agent/secrets.md\n secret_backend_command: <COMMAND_PATH>\n\n## @param secret_backend_arguments - list of strings - optional\n## If secret_backend_command is set, specify here a list of arguments to give to the command at each run.\n secret_backend_arguments:\n\n   - <ARGUMENT_1>\n\n   - <ARGUMENT_2>\n\n## @param secret_backend_output_max_size - integer - optional - default: 1048576\n## The size in bytes of the buffer used to store the command answer (apply to both stdout and stderr)\n secret_backend_output_max_size: 1048576\n\n## @param secret_backend_timeout - integer - optional - default: 30\n## The timeout to execute the command in second\n secret_backend_timeout: 30\n\n## @param secret_backend_skip_checks - boolean - optional - default: false\n## Disable fetching secrets for check configurations\n secret_backend_skip_checks: false\n\n## @param snmp_listener - custom object - optional\n## Creates and schedules a listener to automatically discover your SNMP devices.\n## Discovered devices can then be monitored with the SNMP integration by using\n## the auto_conf.yaml file provided by default.\n snmp_listener:\n\n   @param workers - integer - optional - default: 2\n\n   The number of concurrent tasks used to discover SNMP devices. Increasing this value\n\n   discovers devices faster but at the cost of increased resource consumption.\n\n  \n\n   workers: 2\n\n   @param discovery_interval - integer - optional - default: 3600\n\n   How often to discover new SNMP devices, in seconds. Decreasing this value\n\n   discovers devices faster (within the limit of the time taken to scan subnets)\n\n   but at the cost of increased resource consumption.\n\n  \n\n   discovery_interval: 3600\n\n   @param discovery_allowed_failures - integer - optional - default: 3\n\n   The number of failed requests to a given SNMP device before removing it from the list of monitored\n\n   devices.\n\n   If a device shuts down, the Agent stops monitoring it after `discovery_interval * discovery_allowed_failures` seconds.\n\n  \n\n   discovery_allowed_failures: 3\n\n   @param configs - list - required\n\n   The actual list of configurations used to discover SNMP devices in various subnets.\n\n   Example:\n\n   configs:\n\n    - network: 10.0.0.0/24\n\n      version: 1\n\n      community: public\n\n    - network: 10.0.1.0/28\n\n      community: public\n\n      ignored_ip_addresses:\n\n        - 10.0.1.0\n\n        - 10.0.1.1\n\n  \n\n   configs:\n\n     @param network_address - string - required\n\n     The subnet in CIDR format to scan for SNMP devices.\n\n     All unignored IP addresses in the CIDR range are scanned.\n\n     For optimal discovery time, be sure to use the smallest network mask\n\n     possible as is appropriate for your network topology.\n\n     Ex: 10.0.1.0/24\n\n    \n\n     - network_address: <NETWORK>\n\n     @param ignored_ip_addresses - list of strings - optional\n\n     A list of IP addresses to ignore when scanning the network.\n\n    \n\n     ignored_ip_addresses:\n\n       - <IP_ADDRESS_1>\n\n       - <IP_ADDRESS_2>\n\n     @param port - integer - optional - default: 161\n\n     The UDP port to use when connecting to SNMP devices.\n\n    \n\n     port: 161\n\n     @param snmp_version - integer - optional - default: <BEST_GUESS>\n\n     Set the version of the SNMP protocol. Available options are: `1`, `2` or `3`.\n\n     If unset, the Agent tries to guess the correct version based on other configuration\n\n     parameters, for example: if `user` is set, the Agent uses SNMP v3.\n\n    \n\n     snmp_version: <VERSION>\n\n     @param timeout - integer - optional - default: 5\n\n     The number of seconds before timing out.\n\n    \n\n     timeout: 5\n\n     @param retries - integer - optional - default: 3\n\n     The number of retries before failure.\n\n    \n\n     retries: 3\n\n     @param community_string - string - optional\n\n     Required for SNMP v1 & v2.\n\n     Enclose the community string with single quote like below (to avoid special characters being interpreted).\n\n     Ex: 'public'\n\n    \n\n     community_string: '<COMMUNITY>'\n\n     @param user - string - optional\n\n     The username to connect to your SNMP devices.\n\n     SNMPv3 only.\n\n    \n\n     user: <USERNAME>\n\n     @param authKey - string - optional\n\n     The passphrase to use with your Authentication type.\n\n     SNMPv3 only.\n\n    \n\n     authKey: <AUTHENTICATION_KEY>\n\n     @param authProtocol - string - optional\n\n     The authentication protocol to use when connecting to your SNMP devices.\n\n     Available options are: MD5, SHA.\n\n     Defaults to MD5 when `authentication_key` is specified.\n\n     SNMPv3 only.\n\n    \n\n     authProtocol: <AUTHENTICATION_PROTOCOL>\n\n     @param privKey - string - optional\n\n     The passphrase to use with your privacy protocol.\n\n     SNMPv3 only.\n\n    \n\n     privKey: <PRIVACY_KEY>\n\n     @param privProtocol - string - optional\n\n     The privacy protocol to use when connecting to your SNMP devices.\n\n     Available options are: DES, 3DES, AES, AES192, AES256, AES192C, AES256C.\n\n     Defaults to DES when `privacy_key` is specified.\n\n     SNMPv3 only.\n\n    \n\n     privProtocol: <PRIVACY_PROTOCOL>\n\n     @param context_name - string - optional\n\n     The name of your context (optional SNMP v3-only parameter).\n\n    \n\n     context_name: <CONTEXT_NAME>\n\n     @param ad_identifier - string - optional - default: snmp\n\n     A unique identifier to attach to devices from that subnetwork.\n\n     When configuring the SNMP integration in snmp.d/auto_conf.yaml,\n\n     specify the corresponding ad_identifier at the top of the file.\n\n    \n\n     ad_identifier: snmp\n\n     @param loader - string - optional - default: python\n\n     Check loader to use. Available loaders:\n\n     - core: will use corecheck SNMP integration\n\n     - python: will use python SNMP integration\n\n    \n\n     loader: core\n\n## @param profiling - custom object - optional\n## Enter specific configurations for internal profiling.\n##\n## Please note that:\n##   1. This does *not* enable profiling for user applications.\n##   2. This only enables internal profiling of the agent go runtime.\n##   3. To enable profiling for user apps please refer to\n##      https://docs.datadoghq.com/tracing/profiling/\n##   4. Enabling this feature will incur in billing charges and other\n##      unexpected side-effects (ie. agent profiles showing with your\n##      services).\n##\n## Uncomment this parameter and the one below to enable profiling.\n internal_profiling:\n\n   @param enabled - boolean - optional - default: false\n\n   Enable internal profiling for the Agent process.\n\n  \n\n   enabled: false\n\n", "log collection configuration": "## Log collection Configuration ##\n## @param logs_enabled - boolean - optional - default: false\n## Enable Datadog Agent log collection by setting logs_enabled to true.\n logs_enabled: false\n\n## @param logs_config - custom object - optional\n## Enter specific configurations for your Log collection.\n## Uncomment this parameter and the one below to enable them.\n## See https://docs.datadoghq.com/agent/logs/\n logs_config:\n\n   @param container_collect_all - boolean - optional - default: false\n\n   Enable container log collection for all the containers (see ac_exclude to filter out containers)\n\n  \n\n   container_collect_all: false\n\n   @param logs_dd_url - string - optional\n\n   Define the endpoint and port to hit when using a proxy for logs. The logs are forwarded in TCP\n\n   therefore the proxy must be able to handle TCP connections.\n\n  \n\n   logs_dd_url: <ENDPOINT>:<PORT>\n\n   @param logs_no_ssl - boolean - optional - default: false\n\n   Disable the SSL encryption. This parameter should only be used when logs are\n\n   forwarded locally to a proxy. It is highly recommended to then handle the SSL encryption\n\n   on the proxy side.\n\n  \n\n   logs_no_ssl: false\n\n   @param processing_rules - list of custom objects - optional\n\n   Global processing rules that are applied to all logs. The available rules are\n\n   \"exclude_at_match\", \"include_at_match\" and \"mask_sequences\". More information in Datadog documentation:\n\n   https://docs.datadoghq.com/agent/logs/advanced_log_collection/global-processing-rules\n\n  \n\n   processing_rules:\n\n     - type: <RULE_TYPE>\n\n       name: <RULE_NAME>\n\n       pattern: <RULE_PATTERN>\n\n   @param use_http - boolean - optional - default: false\n\n   By default, logs are sent through TCP, use this parameter\n\n   to send logs in HTTPS batches to port 443\n\n  \n\n   use_http: true\n\n   @param use_tcp - boolean - optional - default: false\n\n   By default, logs are sent through HTTP if possible, use this parameter\n\n   to send logs in TCP\n\n  \n\n   use_tcp: true\n\n   @param use_compression - boolean - optional - default: false\n\n   This parameter is available when sending logs with HTTPS. If enabled, the Agent\n\n   compresses logs before sending them.\n\n  \n\n   use_compression: true\n\n   @param compression_level - integer - optional - default: 6\n\n   The compression_level parameter accepts values from 0 (no compression)\n\n   to 9 (maximum compression but higher resource usage).\n\n  \n\n   compression_level: 6\n\n   @param batch_wait - integer - optional - default: 5\n\n   The maximum time the Datadog Agent waits to fill each batch of logs before sending.\n\n  \n\n   batch_wait: 5\n\n", "trace collection configuration": "## Trace Collection Configuration ##\n## @param apm_config - custom object - optional\n## Enter specific configurations for your trace collection.\n## Uncomment this parameter and the one below to enable them.\n## See https://docs.datadoghq.com/agent/apm/\n apm_config:\n\n   @param enabled - boolean - optional - default: true\n\n   Set to true to enable the APM Agent.\n\n  \n\n   enabled: true\n\n   @param env - string - optional - default: none\n\n   The environment tag that Traces should be tagged with.\n\n   If not set the value will be inherited, in order, from the top level\n\n   \"env\" config option if set and then from the 'env:' tag if present in the\n\n   'tags' top level config option.\n\n  \n\n   env: none\n\n   @param receiver_port - integer - optional - default: 8126\n\n   The port that the trace receiver should listen on.\n\n  \n\n   receiver_port: 8126\n\n   @param receiver_socket - string - optional\n\n   Accept traces through Unix Domain Sockets.\n\n   It is off by default. When set, it must point to a valid socket file.\n\n  \n\n   receiver_socket: <UNIX_SOCKET_PATH>\n\n   @param apm_non_local_traffic - boolean - optional - default: false\n\n   Set to true so the Trace Agent listens for non local traffic,\n\n   i.e if Traces are being sent to this Agent from another host/container\n\n  \n\n   apm_non_local_traffic: false\n\n   @param apm_dd_url - string - optional\n\n   Define the endpoint and port to hit when using a proxy for APM. The traces are forwarded in TCP\n\n   therefore the proxy must be able to handle TCP connections.\n\n  \n\n   apm_dd_url: <ENDPOINT>:<PORT>\n\n   @param extra_sample_rate - float - optional - default: 1.0\n\n   Extra global sample rate to apply on all the traces\n\n   This sample rate is combined to the sample rate from the sampler logic, still promoting interesting traces.\n\n   From 1 (no extra rate) to 0 (don't sample at all)\n\n  \n\n   extra_sample_rate: 1.0\n\n   @param max_traces_per_second - integer - optional - default: 10\n\n   Maximum number of traces per second to sample. The limit is applied over an average over\n\n   a few minutes ; much bigger spikes are possible. Set to 0 to disable the limit.\n\n  \n\n   max_traces_per_second: 10\n\n   @param max_events_per_second - integer - optional - default: 200\n\n   Maximum number of APM events per second to sample.\n\n  \n\n   max_events_per_second: 200\n\n   @param max_memory - integer - optional - default: 500000000\n\n   This value is what the Agent aims to use in terms of memory. If surpassed, the API\n\n   rate limits incoming requests to aim and stay below this value.\n\n   Note: The Agent process is killed if it uses more than 150% of `max_memory`.\n\n   Set the `max_memory` parameter to `0` to disable the memory limitation.\n\n  \n\n   max_memory: 500000000\n\n   @param max_cpu_percent - integer - optional - default: 50\n\n   The CPU percentage that the Agent aims to use. If surpassed, the API rate limits\n\n   incoming requests to aim and stay below this value. Examples: 50 = half a core, 200 = two cores.\n\n   Set `max_cpu_percent` to `0` to disable rate limiting based on CPU usage.\n\n  \n\n   max_cpu_percent: 50\n\n   @param obfuscation - object - optional\n\n   Defines obfuscation rules for sensitive data. Disabled by default.\n\n   See https://docs.datadoghq.com/tracing/guide/agent-obfuscation\n\n  \n\n   obfuscation:\n\n       <OBFUSCATION_CONFIGURATION>\n\n   @param filter_tags - object - optional\n\n   Defines rules by which to filter traces based on tags.\n\n    * require - list of key or key/value strings - traces must have those tags in order to be sent to Datadog\n\n    * reject - list of key or key/value strings - traces with these tags are dropped by the Agent\n\n   Note: Rules take into account the intersection of tags defined.\n\n  \n\n   filter_tags:\n\n       require: [<LIST_OF_KEY_VALUE_TAGS>]\n\n       reject: [<LIST_OF_KEY_VALUE_TAGS>]\n\n   @param replace_tags - list of objects - optional\n\n   Defines a set of rules to replace or remove certain resources, tags containing\n\n   potentially sensitive information.\n\n   Each rules has to contain:\n\n    * name - string - The tag name to replace, for resources use \"resource.name\".\n\n    * pattern - string - The pattern to match the desired content to replace\n\n    * repl - string - what to inline if the pattern is matched\n\n  \n\n   See https://docs.datadoghq.com/tracing/guide/security/replace-rules\n\n  \n\n  \n\n   replace_tags:\n\n     - name: \"<TAG_NAME>\"\n\n       pattern: \"<REGEX_PATTERN>\"\n\n       repl: \"<PATTERN_TO_INLINE>\"\n\n   @param ignore_resources - list of strings - optional\n\n   A blacklist of regular expressions can be provided to disable certain traces based on their resource name\n\n   all entries must be surrounded by double quotes and separated by commas.\n\n  \n\n   ignore_resources: [\"(GET|POST) /healthcheck\"]\n\n   @param log_file - string - optional\n\n   The full path to the file where APM-agent logs are written.\n\n  \n\n   log_file: <APM_LOG_FILE_PATH>\n\n   @param log_throttling - boolean - default: true\n\n   Limits the total number of warnings and errors to 10 for every 10 second interval.\n\n  \n\n   log_throttling: true\n\n   @param profiling - custom object - optional\n\n   Enter specific configurations for internal profiling.\n\n  \n\n   Please note that:\n\n     1. This does *not* enable profiling for user applications.\n\n     2. This only enables internal profiling of the agent go runtime.\n\n     3. To enable profiling for user apps please refer to\n\n        https://docs.datadoghq.com/tracing/profiling/\n\n     4. Enabling this feature will incur in billing charges and other\n\n        unexpected side-effects (ie. agent profiles showing with your\n\n        services).\n\n  \n\n   Uncomment this parameter and the one below to enable profiling.\n\n  \n\n   internal_profiling:\n\n  \n\n     @param enabled - boolean - optional - default: false\n\n     Enable internal profiling for the trace-agent process.\n\n    \n\n     enabled: false\n\n", "appsec configuration": "## AppSec Configuration           ##\n## @param appsec_config - custom object - optional\n## Enter specific configurations for your AppSec collection.\n## Uncomment the parameters `appsec_config` and `enabled` to enable AppSec.\n appsec_config:\n\n   @param enabled - boolean - optional - default: true\n\n   Enable the AppSec proxy in the APM Agent.\n\n  \n\n   enabled: true\n\n   @param appsec_dd_url - string - optional\n\n   Define the endpoint and port to hit when using a proxy for AppSec. Logs are forwarded by TCP;\n\n   therefore, the proxy must be able to handle TCP connections.\n\n  \n\n   appsec_dd_url: <ENDPOINT>:<PORT>\n\n   @param max_payload_size - integer - optional - default: 5242880 (5MB)\n\n   Define the maximum HTTP payload size (the body) in bytes the AppSec proxy allows.\n\n  \n\n   max_payload_size: 5242880\n\n", "process collection configuration": "## Process Collection Configuration ##\n## @param process_config - custom object - optional\n## Enter specific configurations for your Process data collection.\n## Uncomment this parameter and the one below to enable them.\n## See https://docs.datadoghq.com/graphing/infrastructure/process/\n process_config:\n\n   @param enabled - string - optional - default: \"false\"\n\n    A string indicating the enabled state of the Process Agent:\n\n      * \"false\"    : The Agent collects only containers information.\n\n      * \"true\"     : The Agent collects containers and processes information.\n\n      * \"disabled\" : The Agent process collection is disabled.\n\n  \n\n   enabled: \"true\"\n\n   @param expvar_port - string - optional - default: 6062\n\n   Port for the debug endpoints for the process Agent.\n\n  \n\n   expvar_port: 6062\n\n   @param log_file - string - optional\n\n   The full path to the file where process Agent logs are written.\n\n  \n\n   log_file: <PROCESS_LOG_FILE_PATH>\n\n   @param intervals - custom object - optional - default: 10s for normal checks and 2s for others.\n\n   The interval, in seconds, at which the Agent runs each check. If you want consistent\n\n   behavior between real-time, set the `container_realtime` and `process_realtime` intervals to 10.\n\n  \n\n   intervals:\n\n     container: 10\n\n     container_realtime: 2\n\n     process: 10\n\n     process_realtime: 2\n\n   @param blacklist_patterns - list of strings - optional\n\n   A list of regex patterns that exclude processes if matched.\n\n  \n\n   blacklist_patterns:\n\n     - <REGEX>\n\n   @param queue_size - integer - optional - default: 20\n\n   How many check results to buffer in memory when POST fails.\n\n  \n\n   queue_size: 20\n\n   @param max_per_message - integer - optional - default: 100\n\n   The maximum number of processes or containers per message.\n\n  \n\n   max_per_message: 100\n\n   @param dd_agent_bin - string - optional\n\n   Overrides the path to the Agent bin used for getting the hostname. Defaults are:\n\n     * Windows: <AGENT_DIRECTORY>\\embedded\\\\agent.exe\n\n     * Unix: /opt/datadog-agent/bin/agent/agent\n\n  \n\n   dd_agent_bin: <AGENT_BIN_PATH>\n\n   @param dd_agent_env - string - optional - default: \"\"\n\n   Overrides of the environment we pass to fetch the hostname.\n\n  \n\n   dd_agent_env: \"\"\n\n   @param scrub_args - boolean - optional - default: true\n\n   Hide sensitive data on the Live Processes page.\n\n  \n\n   scrub_args: true\n\n   @param custom_sensitive_words - list of strings - optional\n\n   Define your own list of sensitive data to be merged with the default one.\n\n   Read more on Datadog documentation:\n\n   https://docs.datadoghq.com/graphing/infrastructure/process/process-arguments-scrubbing\n\n  \n\n   custom_sensitive_words:\n\n     - 'personal_key'\n\n     - '*token'\n\n     - 'sql*'\n\n     - '*pass*d*'\n\n   @param profiling - custom object - optional\n\n   Enter specific configurations for internal profiling.\n\n  \n\n   Please note that:\n\n     1. This does *not* enable profiling for user applications.\n\n     2. This only enables internal profiling of the agent go runtime.\n\n     3. To enable profiling for user apps please refer to\n\n        https://docs.datadoghq.com/tracing/profiling/\n\n     4. Enabling this feature will incur in billing charges and other\n\n        unexpected side-effects (ie. agent profiles showing with your\n\n        services).\n\n  \n\n   Uncomment this parameter and the one below to enable profiling.\n\n  \n\n   internal_profiling:\n\n  \n\n   @param enabled - boolean - optional - default: false\n\n   Enable internal profiling for the Process Agent process.\n\n  \n\n   enabled: false\n\n", "security agent compliance configuration": "## Security Agent Compliance Configuration ##\n## @param compliance_config - custom object - optional\n## Enter specific configuration for continuous compliance checks.\n compliance_config:\n\n   @param enabled - boolean - optional - default: false\n\n   Set to true to enable continuous compliance checks\n\n  \n\n   enabled: false\n\n   @param dir - string - optional - default: /etc/datadog-agent/compliance.d\n\n   Directory path for compliance checks configuration containing enabled benchmarks\n\n  \n\n   dir: /etc/datadog-agent/compliance.d\n\n   @param check_interval - duration - optional - default: 20m\n\n   Check interval (see  https://golang.org/pkg/time/ParseDuration for available options)\n\n   check_interval: 20m\n\n   @param check_max_events_per_run - integer\n\n   - optional - default: 100\n\n   check_max_events_per_run: 100\n\n", "system probe configuration": "## System Probe Configuration ##\n## @param system_probe_config - custom object - optional\n## Enter specific configurations for your System Probe data collection.\n## Uncomment this parameter and the one below to enable them.\n system_probe_config:\n\n   @param sysprobe_socket - string - optional - default: localhost:3333\n\n   The TCP address where system probes are accessed.\n\n  \n\n   sysprobe_socket: localhost:3333\n\n   @param sysprobe_socket - string - optional - default: /opt/datadog-agent/run/sysprobe.sock\n\n   The full path to the location of the unix socket where system probes are accessed.\n\n  \n\n   sysprobe_socket: /opt/datadog-agent/run/sysprobe.sock\n\n   @param log_file - string - optional - default: /var/log/datadog/system-probe.log\n\n   The full path to the file where system-probe logs are written.\n\n  \n\n   log_file: /var/log/datadog/system-probe.log\n\n   @param profiling - custom object - optional\n\n   Enter specific configurations for internal profiling.\n\n  \n\n   Please note that:\n\n     1. This does *not* enable profiling for user applications.\n\n     2. This only enables internal profiling of the agent go runtime.\n\n     3. To enable profiling for user apps please refer to\n\n        https://docs.datadoghq.com/tracing/profiling/\n\n     4. Enabling this feature will incur in billing charges and other\n\n        unexpected side-effects (ie. agent profiles showing with your\n\n        services).\n\n  \n\n   Uncomment this parameter and the one below to enable profiling.\n\n  \n\n   internal_profiling:\n\n  \n\n     @param enabled - boolean - optional - default: false\n\n     Enable internal profiling for the System Probe process.\n\n    \n\n     enabled: false\n\n", "system probe network configuration": "## System Probe Network Configuration ##\n network_config:\n\n   @param enabled - boolean - optional - default: false\n\n   Set to true to enable the Network Module of the System Probe\n\n  \n\n   enabled: false\n\n", "security agent runtime configuration": "## Security Agent Runtime Configuration ##\n##                                      ##\n## Settings to sent logs to Datadog are ##\n## fetched from section `logs_config`   ##\n runtime_security_config:\n\n   @param enabled - boolean - optional - default: false\n\n   Set to true to enable the Security Runtime Module.\n\n  \n\n   enabled: false\n\n   @param fim_enabled - boolean - optional - default: false\n\n   Set to true to enable the File Integrity Monitoring feature.\n\n   fim_enabled: false\n\n   @param socket - string - optional - default: /opt/datadog-agent/run/runtime-security.sock\n\n   The full path to the location of the unix socket where security runtime module is accessed.\n\n  \n\n   socket: /opt/datadog-agent/run/runtime-security.sock\n\n   @param policies - custom object - optional\n\n   Policy files\n\n   policies:\n\n     @param dir - string - default: /etc/datadog-agent/runtime-security.d\n\n     Path from where the policy files will be loaded\n\n    \n\n     dir: /etc/datadog-agent/runtime-security.d\n\n   @param syscall_monitor - custom object - optional\n\n   Syscall monitoring\n\n  \n\n   syscall_monitor:\n\n     @param enabled - boolean - optional - default: false\n\n     Set to true to enable the Syscall monitoring.\n\n    \n\n      enabled: false\n\n   @param custom_sensitive_words - list of strings - optional\n\n   Define your own list of sensitive data to be merged with the default one.\n\n   Read more on Datadog documentation:\n\n   https://docs.datadoghq.com/graphing/infrastructure/process/process-arguments-scrubbing\n\n  \n\n   custom_sensitive_words:\n\n     - 'personal_key'\n\n     - '*token'\n\n     - 'sql*'\n\n     - '*pass*d*'\n\n## Security Agent Runtime Configuration ##\n##                                      ##\n## Settings to sent logs to Datadog are ##\n## fetched from section `logs_config`   ##\n runtime_security_config:\n\n   @param enabled - boolean - optional - default: false\n\n   Set to true to enable the Security Runtime Module.\n\n  \n\n   enabled: false\n\n   @param socket - string - optional - default: /opt/datadog-agent/run/runtime-security.sock\n\n   The full path to the location of the unix socket where security runtime module is accessed.\n\n  \n\n   socket: /opt/datadog-agent/run/runtime-security.sock\n\n", "dogstatsd configuration": "## DogStatsD Configuration ##\n## @param use_dogstatsd - boolean - optional - default: true\n## Set this option to false to disable the Agent DogStatsD server.\n use_dogstatsd: true\n\n## @param dogstatsd_port - integer - optional - default: 8125\n## Override the Agent DogStatsD port.\n## Note: Make sure your client is sending to the same UDP port.\n dogstatsd_port: 8125\n\n## @param bind_host - string - optional - default: localhost\n## The host to listen on for Dogstatsd and traces. This is ignored by APM when\n## `apm_config.apm_non_local_traffic` is enabled and ignored by DogStatsD when `dogstatsd_non_local_traffic`\n## is enabled. The trace-agent uses this host to send metrics to.\n## The `localhost` default value is invalid in IPv6 environments where dogstatsd listens on \"::1\".\n## To solve this problem, ensure Dogstatsd is listening on IPv4 by setting this value to \"127.0.0.1\".\n bind_host: localhost\n\n## @param dogstatsd_socket - string - optional - default: \"\"\n## Listen for Dogstatsd metrics on a Unix Socket (*nix only). Set to a valid filesystem path to enable.\n dogstatsd_socket: \"\"\n\n## @param dogstatsd_origin_detection - boolean - optional - default: false\n## When using Unix Socket, DogStatsD can tag metrics with container metadata.\n## If running DogStatsD in a container, host PID mode (e.g. with --pid=host) is required.\n dogstatsd_origin_detection: false\n\n## @param dogstatsd_buffer_size - integer - optional - default: 8192\n## The buffer size use to receive statsd packets, in bytes.\n dogstatsd_buffer_size: 8192\n\n## @param dogstatsd_non_local_traffic - boolean - optional - default: false\n## Set to true to make DogStatsD listen to non local UDP traffic.\n dogstatsd_non_local_traffic: false\n\n## @param dogstatsd_stats_enable - boolean - optional - default: false\n## Publish DogStatsD's internal stats as Go expvars.\n dogstatsd_stats_enable: false\n\n## @param dogstatsd_queue_size - integer - optional - default: 1024\n## Configure the internal queue size of the Dogstatsd server.\n## Reducing the size of this queue will reduce the maximum memory usage of the\n## Dogstatsd server but as a trade-off, it could increase the number of packet drops.\n dogstatsd_queue_size: 1024\n\n## @param dogstatsd_stats_buffer - integer - optional - default: 10\n## Set how many items should be in the DogStatsD's stats circular buffer.\n dogstatsd_stats_buffer: 10\n\n## @param dogstatsd_stats_port - integer - optional - default: 5000\n## The port for the go_expvar server.\n dogstatsd_stats_port: 5000\n\n## @param dogstatsd_so_rcvbuf - integer - optional - default: 0\n## The number of bytes allocated to DogStatsD's socket receive buffer (POSIX system only).\n## By default, the system sets this value. If you need to increase the size of this buffer\n## but keep the OS default value the same, you can set DogStatsD's receive buffer size here.\n## The maximum accepted value might change depending on the OS.\n dogstatsd_so_rcvbuf: 0\n\n## @param dogstatsd_metrics_stats_enable - boolean - optional - default: false\n## Set this parameter to true to have DogStatsD collects basic statistics (count/last seen)\n## about the metrics it processsed. Use the Agent command \"dogstatsd-stats\" to visualize\n## those statistics.\n dogstatsd_metrics_stats_enable: false\n\n## @param dogstatsd_tags - list of key:value elements - optional\n## Additional tags to append to all metrics, events and service checks received by\n## this DogStatsD server.\n dogstatsd_tags:\n\n   - <TAG_KEY>:<TAG_VALUE>\n\n## @param dogstatsd_mapper_profiles - list of custom object - optional\n## The profiles will be used to convert parts of metrics names into tags.\n## If a profile prefix is matched, other profiles won't be tried even if that profile matching rules doesn't match.\n## The profiles and matching rules are processed in the order defined in this configuration.\n##\n## For each profile, following fields are available:\n##    name (required): profile name\n##    prefix (required): mapping only applies to metrics with the prefix. If set to `*`, it will match everything.\n##    mappings: mapping rules, see below.\n## For each mapping, following fields are available:\n##    match (required): pattern for matching the incoming metric name e.g. `test.job.duration.*`\n##    match_type (optional): pattern type can be `wildcard` (default) or `regex` e.g. `test\\.job\\.(\\w+)\\.(.*)`\n##    name (required): the metric name the metric should be mapped to e.g. `test.job.duration`\n##    tags (optional): list of key:value pair of tag key and tag value\n##      The value can use $1, $2, etc, that will be replaced by the corresponding element capture by `match` pattern\n##      This alternative syntax can also be used: ${1}, ${2}, etc\n dogstatsd_mapper_profiles:\n\n   - name: <PROFILE_NAME>                         e.g. \"airflow\", \"consul\", \"some_database\"\n\n     prefix: <PROFILE_PREFIX>                     e.g. \"airflow.\", \"consul.\", \"some_database.\"\n\n     mappings:\n\n       - match: <METRIC_TO_MATCH>                 e.g. `test.job.duration.*` to match `test.job.duration.my_job_name`\n\n         match_type: <MATCH_TYPE>                 e.g. `wildcard` or `regex`\n\n         name: <MAPPED_METRIC_NAME>               e.g. `test.job.duration`\n\n         tags:\n\n           <TAG_KEY>: <TAG_VALUE_TO_EXPAND>       e.g. `job_name: \"$1\"`, $1 is replaced by value capture by *\n\n       - match: 'test.worker.*.*.start_time'      to match `test.worker.<worker_type>.<worker_name>.start_time`\n\n         name: 'test.worker.start_time'\n\n         tags:\n\n           worker_type: '$1'\n\n           worker_name: '$2'\n\n       - match: 'test\\.task\\.duration\\.(\\w+)\\.(.*)'      no need to escape in yaml context using single quote\n\n         match_type: regex\n\n         name: 'test.task'\n\n         tags:\n\n           task_type: '$1'\n\n           task_name: '$2'\n\n## @param dogstatsd_mapper_cache_size - integer - optional - default: 1000\n## Size of the cache (max number of mapping results) used by Dogstatsd mapping feature.\n dogstatsd_mapper_cache_size: 1000\n\n## @param dogstatsd_entity_id_precedence - boolean - optional - default: false\n## Disable enriching Dogstatsd metrics with tags from \"origin detection\" when Entity-ID is set.\n dogstatsd_entity_id_precedence: false\n\n## @param statsd_forward_host - string - optional - default: \"\"\n## Forward every packet received by the DogStatsD server to another statsd server.\n## WARNING: Make sure that forwarded packets are regular statsd packets and not \"DogStatsD\" packets,\n## as your other statsd server might not be able to handle them.\n statsd_forward_host: \"\"\n\n## @param statsd_forward_port - integer - optional - default: 0\n## Port or the \"statsd_forward_host\" to forward StatsD packet to.\n statsd_forward_port: 0\n\n## @param statsd_metric_namespace - string - optional - default: \"\"\n## Set a namespace for all StatsD metrics coming from this host.\n## Each metric received is prefixed with the namespace before it's sent to Datadog.\n statsd_metric_namespace: \"\"\n\n## @param metadata_providers - list of custom object - optional\n## Metadata providers, add or remove from the list to enable or disable collection.\n## Intervals are expressed in seconds. You can also set a provider's interval to 0\n## to disable it.\n metadata_providers:\n\n   - name: k8s\n\n     interval: 60\n\n", "jmx configuration": "## JMX Configuration ##\n## @param jmx_custom_jars - list of strings - optional\n## If you only run Autodiscovery tests, jmxfetch might fail to pick up custom_jar_paths\n## set in the check templates. If that is the case, force custom jars here.\n jmx_custom_jars:\n\n   - /jmx-jars/jboss-cli-client.jar\n\n## @param jmx_use_cgroup_memory_limit - boolean - optional - default: false\n## When running in a memory cgroup, openjdk 8u131 and higher can automatically adjust\n## its heap memory usage in accordance to the cgroup/container's memory limit.\n## The Agent set a Xmx of 200MB if none is configured.\n## Note: OpenJDK version < 8u131 or >= 10 as well as other JVMs might fail\n## to start if this option is set.\n jmx_use_cgroup_memory_limit: false\n\n## @param jmx_use_container_support - boolean - optional - default: false\n## When running in a container, openjdk 10 and higher can automatically detect\n## container specific configuration instead of querying the operating system\n## to adjust resources allotted to the JVM.\n## Note: openjdk versions prior to 10 and other JVMs might fail to start if\n## this option is set.\n jmx_use_container_support: false\n\n## @param jmx_log_file - string - optional\n## Path of the log file where JMXFetch logs are written.\n jmx_log_file: <JMXFETCH_LOG_FILE_PATH>\n\n## @param jmx_max_restarts - integer - optional - default: 3\n## Number of JMX restarts allowed in the restart-interval before giving up.\n jmx_max_restarts: 3\n\n## @param jmx_restart_interval - integer - optional - default: 5\n## Duration of the restart interval in seconds.\n jmx_restart_interval: 5\n\n## @param jmx_check_period - integer - optional - default: 15000\n## Duration of the period for check collections in milliseconds.\n jmx_check_period: 15000\n\n## @param jmx_thread_pool_size - integer - optional - default: 3\n## JMXFetch collects multiples instances concurrently. Defines the maximum level of concurrency:\n##   * Higher concurrency increases CPU utilization during metric collection.\n##   * Lower concurrency results in lower CPU usage but may increase the total collection time.\n## A value of 1 processes instances serially.\n jmx_thread_pool_size: 3\n\n## @param jmx_collection_timeout - integer - optional - default: 60\n## Defines the maximum waiting period in seconds before timing up on metric collection.\n jmx_collection_timeout: 60\n\n## @param jmx_reconnection_thread_pool_size - integer - optional - default: 3\n## JMXFetch reconnects to multiples instances concurrently. Defines the maximum level of concurrency:\n##   * Higher concurrency increases CPU utilization during reconnection.\n##   * Lower concurrency results in lower CPU usage but may increase the total reconnection time\n## A value of 1 processes instance reconnections serially.\n jmx_reconnection_thread_pool_size: 3\n\n## @param jmx_reconnection_timeout - integer - optional - default: 60\n## Determines the maximum waiting period in seconds before timing up on instance reconnection.\n jmx_reconnection_timeout: 60\n\n", "logging configuration": "## Logging Configuration ##\n## @param log_level - string - optional - default: info\n## Minimum log level of the Datadog Agent.\n## Valid log levels are: trace, debug, info, warn, error, critical, and off.\n## Note: When using the 'off' log level, quotes are mandatory.\n log_level: 'info'\n\n## @param log_file - string - optional\n## Path of the log file for the Datadog Agent.\n## See https://docs.datadoghq.com/agent/guide/agent-log-files/\n log_file: <AGENT_LOG_FILE_PATH>\n\n## @param log_format_json - boolean - optional - default: false\n## Set to 'true' to output Agent logs in JSON format.\n log_format_json: false\n\n## @param log_to_console - boolean - optional - default: true\n## Set to 'false' to disable Agent logging to stdout.\n log_to_console: true\n\n## @param disable_file_logging - boolean - optional - default: false\n## Set to 'true' to disable logging to the log file.\n disable_file_logging: false\n\n## @param log_file_max_size - custom - optional - default: 10MB\n## Maximum size of one log file. Use either a size (e.g. 10MB) or\n## provide value in bytes: 10485760\n log_file_max_size: 10MB\n\n## @param log_file_max_rolls - integer - optional - default: 1\n## Maximum amount of \"old\" log files to keep.\n## Set to 0 to not limit the number of files to create.\n log_file_max_rolls: 1\n\n## @param log_to_syslog - boolean - optional - default: false\n## Set to 'true' to enable logging to syslog.\n## Note: Even if this option is set to 'false', the service launcher of your environment\n## may redirect the Agent process' stdout/stderr to syslog. In that case, if you wish\n## to disable logging to syslog entirely, set 'log_to_console' to 'false' as well.\n log_to_syslog: false\n\n## @param syslog_uri - string - optional\n## Define a custom remote syslog uri if needed. If 'syslog_uri' is left undefined/empty,\n## a local domain socket connection is attempted.\n syslog_uri: <SYSLOG_URI>\n\n## @param syslog_rfc - boolean - optional - default: false\n## Set to 'true' to output in an RFC 5424-compliant format for Agent logs.\n syslog_rfc: false\n\n## @param syslog_pem - string - optional\n## If TLS enabled, you must specify a path to a PEM certificate here.\n syslog_pem: <PEM_CERTIFICATE_PATH>\n\n## @param syslog_key - string - optional\n## If TLS enabled, you must specify a path to a private key here.\n syslog_key: <PEM_KEY_PATH>\n\n## @param syslog_tls_verify - boolean - optional - default: true\n## If TLS enabled, you may enforce TLS verification here.\n syslog_tls_verify: true\n\n## @param log_format_rfc3339 - boolean - optional - default false\n## If enabled the Agent will log using the RFC3339 format for the log time.\n log_format_rfc3339: false\n\n## @param log_all_goroutines_when_unhealthy - boolean - optional - default false\n## If enabled, when the health probe of an internal component fails, the stack traces\n## of all the goroutines are logged.\n log_all_goroutines_when_unhealthy: false\n\n", "autoconfig configuration": "## Autoconfig Configuration ##\n## @param autoconf_template_dir - string - optional - default: /datadog/check_configs\n## Directory containing configuration templates for Autoconfig.\n autoconf_template_dir: /datadog/check_configs\n\n## @param config_providers - List of custom object - optional\n## The providers the Agent should call to collect checks configurations. Available providers are:\n##   * kubelet - The kubelet provider handles templates embedded in pod annotations.\n##   * docker -  The Docker provider handles templates embedded in container labels.\n##   * clusterchecks - The clustercheck provider retrieves cluster-level check configurations from the cluster-agent.\n##   * kube_services - The kube_services provider watches Kubernetes services for cluster-checks\n##\n## See https://docs.datadoghq.com/guides/autodiscovery/ to learn more\n config_providers:\n\n  - name: kubelet\n\n    polling: true\n\n  - name: docker\n\n    polling: true\n\n  - name: clusterchecks\n\n    grace_time_seconds: 60\n\n  - name: kube_services\n\n    polling: true\n\n  - name: etcd\n\n    polling: true\n\n    template_dir: /datadog/check_configs\n\n    template_url: http://127.0.0.1\n\n    username:\n\n    password:\n\n  - name: consul\n\n    polling: true\n\n    template_dir: datadog/check_configs\n\n    template_url: http://127.0.0.1\n\n    ca_file:\n\n    ca_path:\n\n    cert_file:\n\n    key_file:\n\n    username:\n\n    password:\n\n    token:\n\n  - name: zookeeper\n\n    polling: true\n\n    template_dir: /datadog/check_configs\n\n    template_url: 127.0.0.1\n\n    username:\n\n    password:\n\n## @param extra_config_providers - list of strings - optional\n## Add additional config providers by name using their default settings, and pooling enabled.\n## This list is available as an environment variable binding.\n extra_config_providers:\n\n   - clusterchecks\n\n## @param autoconfig_exclude_features - list of comma separated strings - optional\n## Exclude features automatically detected and enabled by environment autodiscovery.\n## Supported syntax is a list of `(<attribute>:)<regexp>`. Currently only the `name` attribute is supported.\n## When no attribute is present, it defaults to `name:` attribute.\n autoconfig_exclude_features:\n\n  - cloudfoundry\n\n  - containerd\n\n  - cri\n\n  - docker\n\n  - ecsfargate\n\n  - eksfargate\n\n  - kubernetes\n\n  - orchestratorexplorer\n\n## @param autoconfig_include_features - list of comma separated strings - optional\n## Force activation of features (as if they were discovered by environment autodiscovery).\n autoconfig_include_features:\n\n  - cloudfoundry\n\n  - containerd\n\n  - cri\n\n  - docker\n\n  - ecsfargate\n\n  - eksfargate\n\n  - kubernetes\n\n  - orchestratorexplorer\n\n", "container autodiscovery configuration": "## Container Autodiscovery Configuration ##\n## @param container_cgroup_root - string - optional - default: /host/sys/fs/cgroup/\n## Change the root directory to look at to get cgroup statistics.\n## Default if environment variable \"DOCKER_DD_AGENT\" is set to \"/host/sys/fs/cgroup\"\n## and \"/sys/fs/cgroup\" if not.\n container_cgroup_root: /host/sys/fs/cgroup/\n\n## @param container_proc_root - string - optional - default: /host/proc\n## Change the root directory to look at to get proc statistics.\n## Default if environment variable \"DOCKER_DD_AGENT\" is set \"/host/proc\" and \"/proc\" if not.\n container_proc_root: /host/proc\n\n## @param listeners - list of key:value elements - optional\n## Choose \"auto\" if you want to let the Agent find any relevant listener on your host\n## At the moment, the only auto listener supported is Docker\n## If you have already set Docker anywhere in the listeners, the auto listener is ignored\n listeners:\n\n   - name: auto\n\n   - name: docker\n\n## @param extra_listeners - list of strings - optional\n## You can also add additional listeners by name using their default settings.\n## This list is available as an environment variable binding.\n extra_listeners:\n\n   - kubelet\n\n## @param ac_exclude - list of comma separated strings - optional\n## Exclude containers from metrics and AD based on their name or image.\n## If a container matches an exclude rule, it won't be included unless it first matches an include rule.\n## An excluded container won't get any individual container metric reported for it.\n## See: https://docs.datadoghq.com/agent/autodiscovery/#include-or-exclude-containers\n ac_exclude: []\n\n## @param ac_include - list of comma separated strings - optional\n## Include containers from metrics and AD based on their name or image:\n## See: https://docs.datadoghq.com/agent/autodiscovery/#include-or-exclude-containers\n ac_include: []\n\n## @param exclude_pause_container - boolean - optional - default: true\n## Exclude default pause containers from orchestrators.\n## By default the Agent doesn't monitor kubernetes/openshift pause container.\n## They are still counted in the container count (just like excluded containers).\n exclude_pause_container: true\n\n## @param docker_query_timeout - integer - optional - default: 5\n## Set the default timeout value when connecting to the Docker daemon.\n docker_query_timeout: 5\n\n## @param ad_config_poll_interval - integer - optional - default: 10\n## The default interval in second to check for new autodiscovery configurations\n## on all registered configuration providers.\n ad_config_poll_interval: 10\n\n## @param cloud_foundry_garden - custom object - optional\n## Settings for Cloudfoundry application container autodiscovery.\n cloud_foundry_garden:\n\n   @param listen_network - string - optional - default: unix\n\n   The network on which the garden API is listening. Possible values are `unix` or `tcp`\n\n  \n\n   listen_network: unix\n\n   @param listen_address - string - optional - default: /var/vcap/data/garden/garden.sock\n\n   The address on which the garden API is listening.\n\n  \n\n   listen_address: /var/vcap/data/garden/garden.sock\n\n", "cluster check configuration": "## Cluster check Configuration ##\n## @param cluster_checks - custom object - optional\n## Enter specific configurations for your cluster check.\n## The cluster-agent is able to autodiscover cluster resources and dispatch checks on\n## the node-agents (provided the clustercheck config provider is enabled on them).\n## Uncomment this parameter and the one below to enable them.\n## See https://docs.datadoghq.com/agent/kubernetes/cluster/\n cluster_checks:\n\n   @param enabled - boolean - optional - default: false\n\n   Set to true to enable the dispatching logic on the leader cluster-agent.\n\n  \n\n   enabled: false\n\n   @param node_expiration_timeout - integer - optional - default: 30\n\n   Set \"node_expiration_timeout\" time in second after which Node-agents that have not\n\n   queried the cluster-agent are deleted, and their checks re-dispatched to other nodes.\n\n  \n\n   node_expiration_timeout: 30\n\n   @param warmup_duration - integer - optional - default: 30\n\n   Set the \"warmup_duration\" duration in second for the cluster-agent to wait for all\n\n   node-agents to report to it before dispatching configurations.\n\n  \n\n   warmup_duration: 30\n\n   @param cluster_tag_name - string - optional - default: cluster_name\n\n   If a cluster_name value is set or autodetected, a \"<CLUSTER_NAME>\" tag is added\n\n   to all cluster-check configurations sent to the node-agents.\n\n   Set a custom tag name here, or disable it by setting an empty name.\n\n  \n\n   cluster_tag_name: cluster_name\n\n   @param extra_tags - list of key:value elements - optional\n\n   Set a list of additionnal tags can to be added to every cluster-check configuration.\n\n  \n\n   extra_tags:\n\n     - <TAG_KEY>:<TAG_VALUE>\n\n   @param advanced_dispatching_enabled - boolean - optional - default: false\n\n   If advanced_dispatching_enabled is true the leader cluster-agent collects stats\n\n   from the cluster level check runners to optimize the check dispatching logic.\n\n  \n\n   advanced_dispatching_enabled: false\n\n   @param clc_runners_port - integer - optional - default: 5005\n\n   Set the \"clc_runners_port\" used by the cluster-agent client to reach cluster level\n\n   check runners and collect their stats.\n\n  \n\n   clc_runners_port: 5005\n\n", "container detection": "## Container detection ##\n## @param container_cgroup_prefix - string - optional - default: /docker/\n## On hosts with mixed workloads, non-containernized processes can\n## mistakenly be detected as containerized. Use this parameter to\n## tune the detection logic to your system and avoid false-positives.\n container_cgroup_prefix: \"/docker/\"\n\n", "docker tag extraction": "## Docker tag extraction ##\n## @param docker_labels_as_tags - map - optional\n## The Agent can extract container label values and set them as metric tags values associated to a <TAG_KEY>.\n## If you prefix your tag name with `+`, it will only be added to high cardinality metrics (Docker check).\n docker_labels_as_tags:\n\n   <LABEL_NAME>: <TAG_KEY>\n\n   <HIGH_CARDINALITY_LABEL_NAME>: +<TAG_KEY>\n\n## @param docker_env_as_tags - map - optional\n## The Agent can extract environment variables values and set them as metric tags values associated to a <TAG_KEY>.\n## If you prefix your tag name with `+`, it will only be added to high cardinality metrics (Docker check).\n docker_env_as_tags:\n\n   <ENVVAR_NAME>: <TAG_KEY>\n\n", "kubernetes tag extraction": "## Kubernetes tag extraction ##\n## @param kubernetes_pod_labels_as_tags - map - optional\n## The Agent can extract pod labels values and set them as metric tags values associated to a <TAG_KEY>.\n## If you prefix your tag name with +, it will only be added to high cardinality metrics.\n kubernetes_pod_labels_as_tags:\n\n   <POD_LABEL>: <TAG_KEY>\n\n   <HIGH_CARDINALITY_LABEL_NAME>: +<TAG_KEY>\n\n## @param kubernetes_pod_annotations_as_tags - map - optional\n## The Agent can extract annotations values and set them as metric tags values associated to a <TAG_KEY>.\n## If you prefix your tag name with +, it will only be added to high cardinality metrics.\n kubernetes_pod_annotations_as_tags:\n\n   <ANNOTATION>: <TAG_KEY>\n\n   <HIGH_CARDINALITY_ANNOTATION>: +<TAG_KEY>\n\n## @param kubernetes_namespace_labels_as_tags - map - optional\n## The Agent can extract namespace label values and set them as metric tags values associated to a <TAG_KEY>.\n## If you prefix your tag name with +, it will only be added to high cardinality metrics.\n kubernetes_namespace_labels_as_tags:\n\n   <NAMESPACE_LABEL>: <TAG_KEY>\n\n   <HIGH_CARDINALITY_NAMESPACE_LABEL_NAME>: +<TAG_KEY>\n\n", "ecs integration configuration": "## ECS integration Configuration ##\n## @param ecs_agent_container_name - string - optional - default: ecs-agent\n## The ECS Agent container should be autodetected when running with the\n## default (ecs-agent) name. If not, change the container name here:\n ecs_agent_container_name: ecs-agent\n\n## @param ecs_agent_url - string - optional - default: http://localhost:51678\n## The ECS Agent container should be autodetected when running with the\n## default (ecs-agent) name. If not, change the container name the\n## Agent should look for with ecs_agent_container_name, or force a fixed url here:\n ecs_agent_url: http://localhost:51678\n\n## @param ecs_collect_resource_tags_ec2 - boolean - optional - default: false\n## The Agent can collect resource tags from the metadata API exposed by the\n## ECS Agent for tasks scheduled with the EC2 launch type.\n ecs_collect_resource_tags_ec2: false\n\n## @param ecs_resource_tags_replace_colon - boolean - optional - default: false\n## The Agent replaces colon `:` characters in the ECS resource tag keys by underscores `_`.\n ecs_resource_tags_replace_colon: false\n\n## @param ecs_metadata_timeout - integer - optional - default: 500\n## Timeout in milliseconds on calls to the AWS ECS metadata endpoints.\n ecs_metadata_timeout: 500\n\n", "cri integration configuration": "## CRI integration Configuration ##\n## @param cri_socket_path - string - optional - default: \"\"\n## To activate the CRI check, indicate the path of the CRI socket you're using\n## and mount it in the container if needed.\n## If left empty, the CRI check is disabled.\n## see: https://docs.datadoghq.com/integrations/cri/\n cri_socket_path: \"\"\n\n## @param cri_connection_timeout - integer - optional - default: 5\n## Configure the initial connection timeout in seconds.\n cri_connection_timeout: 5\n\n## @param cri_query_timeout - integer - optional - default: 5\n## Configure the timeout in seconds for querying the CRI.\n cri_query_timeout: 5\n\n", "containerd integration configuration": "## Containerd integration Configuration ##\n## @param cri_socket_path - string - optional - default: /var/run/containerd/containerd.sock\n## To activate the Containerd check, indicate the path of the Containerd socket you're using\n## and mount it in the container if needed.\n## see: https://docs.datadoghq.com/integrations/containerd/\n cri_socket_path: /var/run/containerd/containerd.sock\n\n## @param cri_query_timeout - integer - optional - default: 5\n## Configure the timeout in seconds for querying the Containerd API.\n cri_query_timeout: 5\n\n## @param containerd_namespace - string - optional - default: k8s.io\n## Activating the Containerd check also activates the CRI check, as it contains an additional subset of useful metrics.\n## Specify here the namespace that Containerd is using on your system. As the Containerd check\n## only supports Kubernetes, the default value is `k8s.io`\n## https://github.com/containerd/cri/blob/release/1.2/pkg/constants/constants.go#L22-L23\n containerd_namespace: k8s.io\n\n", "kubernetes kubelet connectivity configuration": "## Kubernetes kubelet connectivity Configuration ##\n## @param kubernetes_kubelet_host - string - optional\n## The kubelet host should be autodetected when running inside a pod.\n## If you run into connectivity issues, set the host here according to your cluster setup.\n kubernetes_kubelet_host: <KUBLET_HOST>\n\n## @param kubernetes_http_kubelet_port - integer - optional - default: 10255\n## The kubelet http port should be autodetected when running inside a pod.\n## If you run into connectivity issues, set the http port here according to your cluster setup.\n kubernetes_http_kubelet_port: 10255\n\n## @param kubernetes_https_kubelet_port - integer - optional - default: 10250\n## The kubelet https port should be autodetected when running inside a pod.\n## If you run into connectivity issues, set the https port here according to your cluster setup.\n kubernetes_https_kubelet_port: 10250\n\n## @param kubelet_tls_verify - boolean - optional - default: true\n## Set to false if you don't want the Agent to verify the kubelet's certificate when using HTTPS.\n kubelet_tls_verify: true\n\n## @param kubelet_client_ca - string - optional - default: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n## Kublet client CA file path.\n kubelet_client_ca: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n\n## @param kubelet_auth_token_path - string - optional\n## If authentication is needed, the Agent uses the pod's service account's\n## credentials. If you want to use a different account, or are running the Agent\n## on the host, set a custom token file path here.\n kubelet_auth_token_path: <TOKEN_FILE_PATH>\n\n## @param kubelet_client_crt - string - optional\n## Set a custom Client CRT file path.\n kubelet_client_crt: <CRT_FILE_PATH>\n\n## @param kubelet_client_key - string - optional\n## Set a custom Client key file path.\n kubelet_client_key: <CLIENT_KEY_FILE_PATH>\n\n## @param kubelet_wait_on_missing_container - integer - optional - default: 0\n## On some kubelet versions, containers can take up to a second to\n## register in the podlist. This option allows to wait for up to a given\n## number of seconds (in 250ms chunks) when a container does not exist in the podlist.\n kubelet_wait_on_missing_container: 0\n\n## @param kubelet_cache_pods_duration - integer - optional - default: 5\n## Polling frequency in seconds of the Agent to the kubelet \"/pods\" endpoint.\n kubelet_cache_pods_duration: 5\n\n## @param kubernetes_pod_expiration_duration - integer - optional - default: 900\n## Set the time in second after which the Agent ignores the pods that have exited.\n## Set the duration to 0 to disable this filtering.\n kubernetes_pod_expiration_duration: 900\n\n## @param kubelet_listener_polling_interval - integer - optional - default: 5\n## Polling frequency in seconds at which autodiscovery will query the pod watcher to detect new pods/containers.\n## Note that kubelet_cache_pods_duration needs to be lower than this setting, or autodiscovery will only poll more frequently the same cached data (kubelet_cache_pods_duration controls the cache refresh frequency).\n kubelet_listener_polling_interval: 5\n\n", "kubernetes apiserver integration configuration": "## Kubernetes apiserver integration Configuration ##\n## @param kubernetes_kubeconfig_path - string - optional - default: \"\"\n## When running in a pod, the Agent automatically uses the pod's service account\n## to authenticate with the API server.\n## Provide the path to a custom KubeConfig file if you wish to install the Agent out of a pod\n## or customize connection parameters.\n## See https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/\n kubernetes_kubeconfig_path: \"\"\n\n## @param kubernetes_apiserver_ca_path - string - optional - default: \"\"\n## When running in a pod, the Agent automatically uses the pod's service account CA.\n## Use this option to keep using the InCluster config but overriding the default CA Path.\n## This parameter has no effect if `kubernetes_kubeconfig_path` is set.\n kubernetes_apiserver_ca_path: \"\"\n\n## @param kubernetes_apiserver_tls_verify - boolean - optional - default: true\n## When running in a pod, the Agent automatically uses the pod's service account CA.\n## Use this option to keep using the InCluster config but deactivating TLS verification (in case APIServer CA is not ServiceAccount CA)\n## This parameter has no effect if `kubernetes_kubeconfig_path` is set.\n kubernetes_apiserver_tls_verify: true\n\n## @param kubernetes_apiserver_use_protobuf - boolean - optional - default: false\n## By default, communication with the apiserver is in json format. Setting the following\n## option to true allows communication in the binary protobuf format.\n kubernetes_apiserver_use_protobuf: false\n\n## @param kubernetes_collect_metadata_tags - boolean - optional - default: true\n## Set this to false to disable tag collection for the Agent.\n## Note: In order to collect Kubernetes service names, the Agent needs certain rights.\n## See https://github.com/DataDog/datadog-agent/blob/main/Dockerfiles/agent/README.md#kubernetes\n kubernetes_collect_metadata_tags: true\n\n## @param kubernetes_metadata_tag_update_freq - integer - optional - default: 60\n## Set how often in secons the Agent refreshes the internal mapping of services to ContainerIDs.\n kubernetes_metadata_tag_update_freq: 60\n\n## @param kubernetes_apiserver_client_timeout - integer - optional - default: 10\n## Set the timeout for the Agent when connecting to the Kubernetes API server.\n kubernetes_apiserver_client_timeout: 10\n\n## @param collect_kubernetes_events - boolean - optional - default: false\n## Set `collect_kubernetes_events` to true to enable log collection.\n## Note: leader election must be enabled must be enabled  bellow to to collect events.\n##       Only the leader Agent collects events.\n## See https://github.com/DataDog/datadog-agent/blob/main/Dockerfiles/agent/README.md#event-collection\n collect_kubernetes_events: false\n\n## @param kubernetes_event_collection_timeout - integer - optional - default: 100\n## Set the timeout between two successful event collections in milliseconds.\n kubernetes_event_collection_timeout: 100\n\n## @param leader_election - boolean - optional - default: false\n## Set the parameter to true to enable leader election on this node.\n## See https://github.com/DataDog/datadog-agent/blob/main/Dockerfiles/agent/README.md#leader-election\n leader_election: false\n\n## @param leader_lease_duration - integer - optional - default: 60\n## Set the leader election lease in seconds.\n leader_lease_duration: 60\n\n## @param kubernetes_node_labels_as_tags - map - optional\n## Configure node labels that should be collected and their name as host tags.\n## Note: Some of these labels are redundant with metadata collected by cloud provider crawlers (AWS, GCE, Azure)\n kubernetes_node_labels_as_tags:\n\n   kubernetes.io/hostname: nodename\n\n   beta.kubernetes.io/os: os\n\n## @param cluster_name - string - optional\n## Set a custom kubernetes cluster identifier to avoid host alias collisions.\n## The cluster name can be up to 40 characters with the following restrictions:\n## * Lowercase letters, numbers, and hyphens only.\n## * Must start with a letter.\n## * Must end with a number or a letter.\n##\n## These are the same rules as the ones enforced by GKE:\n## https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1beta1/projects.locations.clusters#Cluster.FIELDS.name\n cluster_name: <CLUSTER_IDENTIFIER>\n\n## @param disable_cluster_name_tag_key - boolean - optional - default: false\n## Disable using the 'cluster_name' tag key to submit orchestrator cluster name tag.\n## The Agent will continue sending the cluster name tag with 'kube|ecs_cluster_name' key\n## regardless of the value of this parameter.\n disable_cluster_name_tag_key: false\n\n", "cloud foundry bbs configuration for autodiscovery": "## Cloud Foundry BBS Configuration for Autodiscovery ##\n## @param cloud_foundry_bbs - custom object - optional\n## This section configures how the Cluster Agent accesses BBS API to gather information\n## necessary for autodiscovery on BBS-based Cloud Foundry deployments.\n cloud_foundry_bbs:\n\n   @param url - string - optional - default: https://bbs.service.cf.internal:8889\n\n   URL of the BBS API.\n\n  \n\n   url: https://bbs.service.cf.internal:8889\n\n   @param poll_interval - integer - optional - default: 15\n\n   Refresh rate of BBS API, in seconds. Values lower than 10 might influence\n\n   performance of other operations in the cluster.\n\n  \n\n   poll_interval: 15\n\n   @param ca_file - string - optional - default: \"\"\n\n   PEM-encoded CA certificate used when connecting to the BBS API.\n\n  \n\n   ca_file: \"\"\n\n   @param cert_file - string - optional - default: \"\"\n\n   PEM-encoded client certificate used when connecting to the BBS API.\n\n  \n\n   cert_file: \"\"\n\n   @param key_file - string - optional - default: \"\"\n\n   PEM-encoded client key used when connecting to the BBS API.\n\n  \n\n   key_file: \"\"\n\n   @param env_include - List of strings - optional - default: []\n\n   List of regular expressions to allow a set of environment variables to be included as container tags\n\n  \n\n   env_include: []\n\n   @param env_exclude - List of strings - optional - default: []\n\n   List of regular expressions to forbid a set of environment variables to be included as container tags\n\n  \n\n   env_exclude: []\n\n", "cloud foundry cloud controller configuration for autodiscovery": "## Cloud Foundry Cloud Controller Configuration for Autodiscovery ##\n## @param cloud_foundry_cc - custom object - optional\n## This section configures how the Cluster Agent accesses CC API to gather information\n## necessary for autodiscovery on Cloud Foundry deployments.\n cloud_foundry_cc:\n\n   @param url - string - optional - default: https://cloud-controller-ng.service.cf.internal:9024\n\n   URL of the CC API.\n\n  \n\n   url: https://cloud-controller-ng.service.cf.internal:9024\n\n   @param client_id - string - optional\n\n   Client ID for oauth with UAA to get a token to access the CC API.\n\n  \n\n   client_id: <UAA_CLIENT_ID>\n\n   @param client_secret - string - optional\n\n   Client ID for oauth with UAA to get a token to access the CC API.\n\n  \n\n   client_secret: <UAA_CLIENT_SECRET>\n\n   @param skip_ssl_validation - bool - optional - default: false\n\n   Whether or not to skip SSL validation when interacting with CC API.\n\n  \n\n   skip_ssl_validation: false\n\n   @param poll_interval - integer - optional - default: 60\n\n   Refresh rate of CC API, in seconds. Values lower than 10 might influence\n\n   performance of other operations in the cluster.\n\n  \n\n   poll_interval: 60\n\n   @param apps_batch_size - integer - optional - default: 5000\n\n   Number of apps per page to collect when calling the list apps endpoint of the CC API. Max 5000.\n\n  \n\n   apps_batch_size: 5000\n\n", "snmp configuration": "## SNMP Configuration ##\n## @param snmp_traps_enabled - boolean - optional - default: false\n## Set to true to enable collection of traps.\n snmp_traps_enabled: false\n\n## @param snmp_traps_config - custom object - optional\n## This section configures SNMP traps collection. Traps are forwarded as logs to Datadog.\n## NOTE: This feature is currently **EXPERIMENTAL**. Both behavior and configuration options may\n## change in the future. Only SNMPv2 is supported.\n snmp_traps_config:\n\n   @param port - integer - optional - default: 162\n\n   The UDP port to use when listening for incoming trap packets.\n\n  \n\n   port: 162\n\n   @param community_strings - list of strings - required\n\n   A list of known SNMPv2 community strings that devices can use to send traps to the Agent.\n\n   Traps with an unknown community string are ignored.\n\n   Enclose the community string with single quote like below (to avoid special characters being interpreted).\n\n   Must be non-empty.\n\n  \n\n   community_strings:\n\n     - '<COMMUNITY_1>'\n\n     - '<COMMUNITY_2>'\n\n   @param bind_host - string - optional\n\n   The hostname to listen on for incoming trap packets.\n\n   Defaults to the global `bind_host` config option value.\n\n  \n\n   bind_host: <BIND_HOST>\n\n   stop_timeout - float - optional - default: 5.0\n\n   The maximum number of seconds to wait for the trap server to stop when the Agent shuts down.\n\n  \n\n   stop_timeout: 5.0\n\n"}